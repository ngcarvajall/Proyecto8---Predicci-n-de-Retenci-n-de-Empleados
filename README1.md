
# ğŸ“Š PredicciÃ³n de RotaciÃ³n de Empleados: Modelos de Machine Learning

## ğŸ“– DescripciÃ³n

Este proyecto aborda un problema crucial para los departamentos de Recursos Humanos: predecir quÃ© empleados tienen mayor probabilidad de dejar la empresa en el prÃ³ximo aÃ±o. A partir de datos histÃ³ricos, hemos desarrollado y evaluado modelos de Machine Learning para identificar patrones y tendencias en la rotaciÃ³n laboral.

El enfoque no solo es tÃ©cnico, sino tambiÃ©n analÃ­tico, explorando preguntas como:
- Â¿Es la satisfacciÃ³n laboral un predictor clave?
- Â¿Las largas horas de trabajo o las relaciones tensas con los jefes afectan la decisiÃ³n de quedarse?
- Â¿QuÃ© papel juegan las promociones o aumentos de salario?

Los resultados no solo buscan ser precisos, sino tambiÃ©n Ãºtiles para tomar decisiones informadas en la gestiÃ³n del talento.

---

## ğŸ—‚ï¸ Estructura del Proyecto

### **DistribuciÃ³n de Carpetas**
```
â”œâ”€â”€ Datos/                # Datos originales y transformados
â”‚   â”œâ”€â”€ Datos_Mod1/       # Datos del Modelo 1
â”‚   â”œâ”€â”€ Datos_Mod2/       # Datos del Modelo 2
â”‚   â”œâ”€â”€ Datos_Mod3/       # Datos del Modelo 3
â”œâ”€â”€ Modelos/              # Archivos de modelos entrenados y Notebooks de cada modelo
â”‚   â”œâ”€â”€ Modelo 1/
â”‚   â”‚   â”œâ”€â”€ 1_EDA.ipynb              # ExploraciÃ³n de datos
â”‚   â”‚   â”œâ”€â”€ 2_Estandarizar.ipynb     # Escalado y estandarizaciÃ³n
â”‚   â”‚   â”œâ”€â”€ 3_Encoding.ipynb         # CodificaciÃ³n de variables
â”‚   â”‚   â”œâ”€â”€ 4_MÃ©tricas.ipynb         # EvaluaciÃ³n del modelo
â”‚   â”œâ”€â”€ Modelo 2/
â”‚   â”‚   â”œâ”€â”€ 1_EDA.ipynb              # ExploraciÃ³n de datos
â”‚   â”‚   â”œâ”€â”€ 2_OUTLIERS.ipynb         # Tratamiento de outliers
â”‚   â”‚   â”œâ”€â”€ 3_Estandarizar.ipynb     # Escalado y estandarizaciÃ³n
â”‚   â”‚   â”œâ”€â”€ 4_MÃ©tricas.ipynb         # EvaluaciÃ³n del modelo
â”‚   â”‚   â”œâ”€â”€ 5_MÃ©tricas_Dif.ipynb     # Comparativa de mÃ©tricas
â”‚   â”œâ”€â”€ Modelo 3/
â”‚   â”‚   â”œâ”€â”€ 1_EDA.ipynb              # ExploraciÃ³n de datos
â”‚   â”‚   â”œâ”€â”€ 2_OUTLIERS.ipynb         # Tratamiento de outliers
â”‚   â”‚   â”œâ”€â”€ 3_Estandarizar.ipynb     # Escalado y estandarizaciÃ³n
â”‚   â”‚   â”œâ”€â”€ 4_MÃ©tricas.ipynb         # EvaluaciÃ³n del modelo
â”‚   â”‚   â”œâ”€â”€ 5_MÃ©tricas_copy.ipynb    # Comparativa de mÃ©tricas
â”‚   â”‚   â”œâ”€â”€ API.ipynb                # ImplementaciÃ³n de la API de predicciÃ³n
â”‚   â”‚   â”œâ”€â”€ main.py                  # Script principal
â”‚   â”‚   â”œâ”€â”€ Streamlit.py             # Interfaz con Streamlit
â”œâ”€â”€ src/                  # Scripts de procesamiento y modelado
â”œâ”€â”€ MÃ©tricas/             # Reportes de mÃ©tricas de evaluaciÃ³n
â”œâ”€â”€ README.md             # DescripciÃ³n del proyecto
```

---

## ğŸ› ï¸ InstalaciÃ³n y Requisitos

Este proyecto utiliza Python 3.8 y las siguientes bibliotecas:

- [pandas](https://pandas.pydata.org/)
- [numpy](https://numpy.org/)
- [scikit-learn](https://scikit-learn.org/stable/)
- [imbalanced-learn](https://imbalanced-learn.org/stable/)
- [matplotlib](https://matplotlib.org/)
- [seaborn](https://seaborn.pydata.org/)
- [xgboost](https://xgboost.readthedocs.io/)
- [streamlit](https://streamlit.io/)

### InstalaciÃ³n:
1. Clona este repositorio:
   ```bash
   git clone <URL DEL REPOSITORIO>
   ```
2. Instala las dependencias:
   ```bash
   pip install -r requirements.txt
   ```

---

## ğŸ“Š Resultados y Conclusiones

### Modelo 1:
- **Duplicados:** Se descubriÃ³ una gran cantidad de duplicados al eliminar la columna `EmployeeID`, lo que afecta la calidad del modelo.
- **Nulos:** Las variables categÃ³ricas fueron completadas con "Desconocido" y las numÃ©ricas mediante `IterativeImputer`.
- **Balanceo:** Este modelo no tiene balanceo, por lo que la variable respuesta "Attrition" estÃ¡ desbalanceada.
- **ConclusiÃ³n:** Las mÃ©tricas del modelo, especialmente usando XGBoost, son altas, pero reflejan un sobreajuste debido a los duplicados (mÃ¡s del 60% de los datos del test estÃ¡n en el entrenamiento).

### Modelo 2:
- **ReducciÃ³n de datos:** Sin duplicados, solo queda el 40% de los datos originales.
- **Outliers:** Se eliminaron los outliers al 100% basados en vecinos 15, 25, y 35.
- **Balanceo:** Este modelo tampoco tiene balanceo, lo que afecta las mÃ©tricas.
- **ConclusiÃ³n:** Decision Tree tuvo el mejor desempeÃ±o, pero las mÃ©tricas fueron significativamente peores debido al desbalanceo.

### Modelo 3:
- **Balanceo:** Se usaron tÃ©cnicas de balanceo como Tomek y SMOTENC para equilibrar la variable respuesta en un 55-45.
- **Resultados:** Este modelo es el mÃ¡s robusto, con mÃ©tricas mÃ¡s realistas y generalizaciÃ³n adecuada.
- **ConclusiÃ³n:** Las mejores mÃ©tricas se obtuvieron con XGBoost y Gradient Boosting.

### Comparativa Final:
| **Modelo**          | **GeneralizaciÃ³n** | **Sobreajuste** | **MÃ©tricas en test** | **Velocidad** | **Comentario**                      |
|----------------------|--------------------|-----------------|----------------------|---------------|--------------------------------------|
| **RegresiÃ³n logÃ­stica** | Alta               | Bajo            | Buenas (0.87-0.88)  | Muy alta      | Consistente, eficiente, confiable.  |
| **XGBoost**          | Media              | Alto            | Muy buenas (0.91)   | Moderada      | Alto rendimiento pero sobreajusta.  |
| **Random Forest**    | Media              | Alto            | Muy buenas (0.91)   | Baja          | Costoso y sobreajustado.            |
| **Gradient Boosting**| Moderada           | Moderado        | Buenas (0.88-0.90)  | Moderada      | Competitivo, buen equilibrio.       |
| **Decision Tree**    | Baja               | Bajo            | DÃ©biles (0.79)      | Moderada      | Modelo menos competitivo.           |

---

## ğŸ”„ PrÃ³ximos Pasos

- Implementar tÃ©cnicas adicionales de feature engineering para mejorar la precisiÃ³n.
- Evaluar otros modelos como LightGBM o CatBoost para comparar rendimiento.
- Automatizar el pipeline de preprocesamiento y entrenamiento.

---

## âœ’ï¸ Autor

- **Nelson Carvajal** - [GitHub](https://github.com/ngcarvajall)
